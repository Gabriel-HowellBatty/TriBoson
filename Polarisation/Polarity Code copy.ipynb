{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import json\n",
    "import numpy as np\n",
    "from pylhe import read_lhe_with_attributes, read_num_events\n",
    "import itertools\n",
    "import json\n",
    "import math\n",
    "import vector\n",
    "import mplhep as hep\n",
    "from scipy.optimize import curve_fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Data Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_all_particle_data(lhe_file):\n",
    "    events = read_lhe_with_attributes(lhe_file)\n",
    "    num_events = read_num_events(lhe_file)\n",
    "\n",
    "    particle_data = []\n",
    "\n",
    "    for event_index, event in enumerate(itertools.islice(events, num_events)):\n",
    "        for particle in event.particles:\n",
    "            particle_data.append({\n",
    "                'event': event_index,\n",
    "                'id': particle.id,\n",
    "                'px': particle.px,\n",
    "                'py': particle.py,\n",
    "                'pz': particle.pz,\n",
    "                'E': particle.e,\n",
    "                'status': particle.status,\n",
    "                'helicity': getattr(particle, 'spin', None)\n",
    "            })\n",
    "\n",
    "    return particle_data\n",
    "\n",
    "def extract_metadata_from_lhe(lhe_file):\n",
    "    cross_section = None\n",
    "    com_energy = None\n",
    "    num_events = None\n",
    "\n",
    "    with open(lhe_file, 'r') as file:\n",
    "        for line in file:\n",
    "            if \"Number of Events\" in line:\n",
    "                num_events = int(line.split(\":\")[1].strip())\n",
    "\n",
    "            if \"Integrated weight (pb)\" in line:\n",
    "                cross_section = float(line.split(\":\")[1].strip())\n",
    "\n",
    "            if \"<init>\" in line:\n",
    "                init_line = next(file).strip().split()\n",
    "                beam_energy_1 = float(init_line[2])\n",
    "                beam_energy_2 = float(init_line[3])\n",
    "                com_energy = (beam_energy_1 + beam_energy_2) / 1000  # TeV\n",
    "                break\n",
    "\n",
    "    return {\"cross_section\": cross_section, \"center_of_mass_energy\": com_energy, \"number_of_events\": num_events}\n",
    "\n",
    "\n",
    "def filter_by_id(particle_data, particle_id):\n",
    "    return [particle for particle in particle_data if particle['id'] == particle_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing Momentums "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_four_vector(data_set):\n",
    "\n",
    "    four_vector = vector.array({\"E\": [data[\"E\"] for data in data_set], \n",
    "                                \"px\": [data[\"px\"] for data in data_set], \n",
    "                                \"py\": [data[\"py\"] for data in data_set], \n",
    "                                \"pz\": [data[\"pz\"] for data in data_set]})\n",
    "    \n",
    "    return four_vector\n",
    "\n",
    "def construct_three_momentum(four_vector):\n",
    "\n",
    "    three_momentum = vector.array({\"px\": four_vector.px, \n",
    "                                   \"py\": four_vector.py, \n",
    "                                   \"pz\": four_vector.pz})\n",
    "    return three_momentum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Invariant Mass Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def invariant_mass_check(vector_1, vector_2):\n",
    "    inv_masss_1 = vector_1.E**2 - ( vector_1.px**2 + vector_1.py**2 + vector_1.pz**2 )\n",
    "    inv_masss_2 = vector_2.E**2 - ( vector_2.px**2 + vector_2.py**2 + vector_2.pz**2 )\n",
    "\n",
    "    mass_diff = np.isclose(inv_masss_1, inv_masss_2, atol=1e-7)\n",
    "    \n",
    "    if np.all(mass_diff):\n",
    "        return\n",
    "\n",
    "    else:\n",
    "        changed_indices = np.where(~mass_diff)[0]\n",
    "        for idx in changed_indices:\n",
    "            print(f\"Warning: Invariant mass changed at index {idx}! Initial: {vector_1.mass[idx]}, Final: {vector_2.mass[idx]}\")\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Momentum Conservation Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def momentum_conservation_check(muon_vector, anti_muon_vector):\n",
    "\n",
    "    total_px = muon_vector.px + anti_muon_vector.px\n",
    "    total_py = muon_vector.py + anti_muon_vector.py\n",
    "    total_pz = muon_vector.pz + anti_muon_vector.pz\n",
    "\n",
    "    px_check = np.isclose(total_px, 0, atol=1e-5)\n",
    "    py_check = np.isclose(total_py, 0, atol=1e-5)\n",
    "    pz_check = np.isclose(total_pz, 0, atol=1e-5)\n",
    "\n",
    "    # Check for px\n",
    "    if np.all(px_check):\n",
    "        return\n",
    "    else:\n",
    "        failed_indices = np.where(~px_check)[0]\n",
    "        for idx in failed_indices:\n",
    "            print(f\"Warning: Total px failed at index {idx}: Value = {total_px[idx]}\")\n",
    "\n",
    "    # Check for py\n",
    "    if np.all(py_check):\n",
    "        return\n",
    "    else:\n",
    "        failed_indices = np.where(~py_check)[0]\n",
    "        for idx in failed_indices:\n",
    "            print(f\"Warning: Total py failed at index {idx}: Value = {total_py[idx]}\")\n",
    "\n",
    "    # Check for pz\n",
    "    if np.all(pz_check):\n",
    "        return\n",
    "    else:\n",
    "        failed_indices = np.where(~pz_check)[0]\n",
    "        for idx in failed_indices:\n",
    "            print(f\"Warning: Total pz failed at index {idx}: Value = {total_pz[idx]}\")\n",
    "\n",
    "    # Final summary\n",
    "    overall_passed = np.all(px_check) and np.all(py_check) and np.all(pz_check)\n",
    "    if overall_passed:\n",
    "        return\n",
    "    else:\n",
    "        print(\"Momentum conservation check failed.\")\n",
    "\n",
    "    return overall_passed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rotation Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotation_check(original_vector, rotated_vector, rotation_axis, tolerance=1e-6):\n",
    "\n",
    "\n",
    "    # Normalize the rotation axis\n",
    "    rotation_axis_norm = abs(rotation_axis)\n",
    "    if rotation_axis_norm < tolerance:\n",
    "        print(\"The rotation axis is too small or zero.\")\n",
    "        return False\n",
    "\n",
    "    rotation_axis_normalized = [\n",
    "        rotation_axis.px / rotation_axis_norm,\n",
    "        rotation_axis.py / rotation_axis_norm,\n",
    "        rotation_axis.pz / rotation_axis_norm\n",
    "    ]\n",
    "\n",
    "    # Normalize original and rotated vectors\n",
    "    original_norm = abs(original_vector)\n",
    "    rotated_norm = abs(rotated_vector)\n",
    "\n",
    "    # Check if both vectors are non-zero\n",
    "    if np.all(original_norm < tolerance) or np.all(rotated_norm < tolerance):\n",
    "        print(\"One of the vectors is too small or zero.\")\n",
    "        return False\n",
    "\n",
    "    # Get the angle between the original and rotated vectors using the dot product\n",
    "    dot_product = (rotation_axis.px * rotated_vector.px +\n",
    "                   rotation_axis.py * rotated_vector.py +\n",
    "                   rotation_axis.pz * rotated_vector.pz)\n",
    "\n",
    "    angle = np.arccos(dot_product / (rotation_axis_norm * rotated_norm))\n",
    "    angle_deg = np.degrees(angle)\n",
    "\n",
    "    # Check the angle to determine if the rotation is correct\n",
    "    # The expected angle depends on your application; you can set it or calculate it based on the specific rotation\n",
    "    expected_angle_1 = np.full(angle_deg.shape, 0)  # Same size as angle_deg\n",
    "    expected_angle_2 = np.full(angle_deg.shape, 180.0)  # Same size as angle_deg\n",
    "    \n",
    "    angle_diff_1 = np.isclose(angle_deg, expected_angle_1, atol=tolerance)\n",
    "    angle_diff_2 = np.isclose(angle_deg, expected_angle_2, atol=tolerance)\n",
    "    combined_angle_diff = np.logical_or(angle_diff_1, angle_diff_2)\n",
    "\n",
    "\n",
    "    if np.all(combined_angle_diff):\n",
    "        return\n",
    "\n",
    "    else:\n",
    "        changed_indices = np.where(~combined_angle_diff)[0]\n",
    "        for idx in changed_indices:\n",
    "            print(f\"Warning: Rotation check failed at Index {idx}.\"\n",
    "              f\"Calculated angle: {angle_deg[idx]} degrees.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rotation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_vector(affected_vector, rotation_axes, rotation_angles):\n",
    "\n",
    "    rotated_x = np.array(\n",
    "        (np.cos(rotation_angles) + (1 - np.cos(rotation_angles)) * rotation_axes.x**2) * affected_vector.x +\n",
    "        (rotation_axes.x * rotation_axes.y * (1 - np.cos(rotation_angles))) * affected_vector.y +\n",
    "        rotation_axes.y * np.sin(rotation_angles) * affected_vector.z\n",
    "    )\n",
    "    \n",
    "    rotated_y = np.array(\n",
    "        rotation_axes.px * rotation_axes.py * (1 - np.cos(rotation_angles)) * affected_vector.px +\n",
    "        (np.cos(rotation_angles) + (1 - np.cos(rotation_angles)) * rotation_axes.py**2) * affected_vector.py -\n",
    "        rotation_axes.px * np.sin(rotation_angles) * affected_vector.z\n",
    "    )\n",
    "        \n",
    "    rotated_z = np.array(\n",
    "        -rotation_axes.py * np.sin(rotation_angles) * affected_vector.px +\n",
    "        rotation_axes.px * np.sin(rotation_angles) * affected_vector.py +\n",
    "        np.cos(rotation_angles) * affected_vector.z\n",
    "    )\n",
    "\n",
    "    rotated_vector = vector.array({\"E\": affected_vector.E, \"px\": rotated_x, \"py\": rotated_y,\"pz\": rotated_z}) \n",
    "\n",
    "    return rotated_vector\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boost Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boost_vector(affected_vector, reference_vector):\n",
    "    \n",
    "    beta = reference_vector.pz / reference_vector.E\n",
    "    gamma = 1 / np.sqrt(1 - beta**2)\n",
    "\n",
    "    E_boosted = gamma * (affected_vector.E - beta*affected_vector.pz)\n",
    "    pz_boosted = gamma * (affected_vector.pz - beta * affected_vector.E )\n",
    "    px_boosted = affected_vector.px\n",
    "    py_boosted = affected_vector.py\n",
    "\n",
    "    boosted_vector = vector.array({\"E\": E_boosted, \"px\": px_boosted, \"py\": py_boosted,\"pz\": pz_boosted}) \n",
    "\n",
    "    return boosted_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rotate and Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_and_boost(affected_vector, reference_vector, axis):\n",
    "\n",
    "    # Define Three Vectors\n",
    "    affected_three_vector = construct_three_momentum(affected_vector)\n",
    "    reference_three_vector = construct_three_momentum(reference_vector)\n",
    "\n",
    "    # Finding Rotaton Axes and Angles\n",
    "    rotation_axes = reference_three_vector.cross(axis).unit()\n",
    "    cos_theta = reference_three_vector.dot(axis) / abs(reference_three_vector) * abs(axis)\n",
    "    rotation_angles = np.arccos(cos_theta)\n",
    "\n",
    "    # Rotate reference vector\n",
    "    rotated_reference_four_vector = rotate_vector(reference_vector, rotation_axes, rotation_angles)\n",
    "    rotated_reference_three_vector = vector.array({\"px\": rotated_reference_four_vector.px, \"py\": rotated_reference_four_vector.py,\"pz\": rotated_reference_four_vector.pz}) \n",
    "    invariant_mass_check(reference_vector, rotated_reference_four_vector)\n",
    "    rotation_check(reference_three_vector, rotated_reference_three_vector, axis)\n",
    "\n",
    "    # Rotate affected vector\n",
    "    rotated_affected_four_vector = rotate_vector(affected_vector, rotation_axes, rotation_angles)\n",
    "    rotated_affected_three_vector = vector.array({\"px\": rotated_affected_four_vector.px, \"py\": rotated_affected_four_vector.py,\"pz\": rotated_affected_four_vector.pz}) \n",
    "    invariant_mass_check(affected_vector, rotated_affected_four_vector)\n",
    "\n",
    "    # Boost the affected vector\n",
    "    rotated_boosted_affected_vector = boost_vector(rotated_affected_four_vector, rotated_reference_four_vector )\n",
    "    invariant_mass_check(rotated_affected_four_vector, rotated_boosted_affected_vector)\n",
    "\n",
    "    return rotated_boosted_affected_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Angle Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_polar_angle(four_vector):\n",
    "    cos_theta =  four_vector.pz / np.sqrt(four_vector.px**2 + four_vector.py**2 + four_vector.pz**2)\n",
    "    theta = np.arccos(cos_theta)\n",
    "    return theta\n",
    "\n",
    "def find_azimuthal_angle(four_vector):\n",
    "    phi = np.arctan2(four_vector.py, four_vector.px)\n",
    "    return phi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helicity Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def z_helicity_function(cos_theta, fL, fR, f0):\n",
    "    cv = -1/2 + 2* np.sin(0.23152)**2\n",
    "    ca = -1/2\n",
    "    alpha = (2*cv*ca)/ (cv**2+ca**2)\n",
    "    \"\"\"The fitting function with the provided equation.\"\"\"\n",
    "    term1 = (3/8) * fL * (1 + 2 * alpha * cos_theta + cos_theta**2)\n",
    "    term2 = (3/8) * fR * (1 + cos_theta**2 - 2 * alpha * cos_theta)\n",
    "    term3 = (3/4) * f0 * (1 - cos_theta**2)\n",
    "    return term1 + term2 + term3\n",
    "\n",
    "def w_helicity_function(cos_theta, fL, fR, f0):\n",
    "    term1 = (3/8) * fL * (1 - cos_theta)**2\n",
    "    term2 = (3/8) * fR * (1 + cos_theta)**2\n",
    "    term3 = (3/4) * f0 * (1-cos_theta**2)  \n",
    "    return term1 + term2 + term3\n",
    "\n",
    "def anti_w_helicity_function(cos_theta, fL, fR, f0):\n",
    "    term1 = (3/8) * fL * (1 + cos_theta)**2\n",
    "    term2 = (3/8) * fR * (1 - cos_theta)**2\n",
    "    term3 = (3/4) * f0 * (1-cos_theta**2)  \n",
    "    return term1 + term2 + term3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_reduced_chi_squared(observed_values, expected_values, error, degrees_of_freedom):\n",
    "    chi_squared = np.sum(((observed_values - expected_values) ** 2) / error**2)\n",
    "    reduced_chi_squared = chi_squared / degrees_of_freedom\n",
    "    return reduced_chi_squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_helicity_fractions(data, boson_type, cross_section, num_events, com_energy):\n",
    "\n",
    "    luminosity = num_events / cross_section\n",
    "\n",
    "    # Filter out NaN and infinite values\n",
    "    valid_data = data[np.isfinite(data)]\n",
    "    cos_theta_data = np.cos(valid_data)\n",
    "    cos_theta_bins = np.linspace(-1, 1, 50)\n",
    "\n",
    "    # Set ATLAS style if mplhep is available\n",
    "    plt.style.use(hep.style.ATLAS)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 6), dpi=100)\n",
    "\n",
    "    # Calculate histogram values without weights, for accurate error calculation\n",
    "    raw_counts, bins = np.histogram(cos_theta_data, bins=cos_theta_bins)\n",
    "    bin_centers = 0.5 * (bins[:-1] + bins[1:])  # Calculate bin centers\n",
    "\n",
    "    # Calculate errors before applying weights\n",
    "    errors = np.sqrt(raw_counts)  # Standard error for each bin (sqrt of count)\n",
    "\n",
    "    # Define weights per event for differential cross-section normalization\n",
    "    weight_per_event = 1 / (luminosity * (cos_theta_bins[1] - cos_theta_bins[0]) * cross_section)\n",
    "\n",
    "    # Apply weights to histogram counts and errors\n",
    "    hist_values = raw_counts * weight_per_event\n",
    "    errors = errors * weight_per_event\n",
    "\n",
    "    # Plot the histogram as a line plot with steps and add error bars\n",
    "    ax.plot(bin_centers, hist_values, drawstyle='steps-mid', color='blue', linewidth=1.5,\n",
    "            label=r'$\\frac{d\\sigma}{d(\\cos \\theta)}$')\n",
    "    ax.errorbar(bin_centers, hist_values, yerr=errors, fmt='o', color='green', capsize=3, markersize=4)\n",
    "\n",
    "    # Select helicity function based on boson type\n",
    "    if boson_type == \"Z\":\n",
    "        helicity_function = z_helicity_function\n",
    "    elif boson_type == \"W+\":\n",
    "        helicity_function = w_helicity_function\n",
    "    elif boson_type == \"W-\":\n",
    "        helicity_function = anti_w_helicity_function\n",
    "\n",
    "    # Fitting\n",
    "    initial_guess = [0.5, 0.1, 0.1]\n",
    "    bounds = (0, 1)\n",
    "\n",
    "    popt, pcov = curve_fit(helicity_function, bin_centers, hist_values, sigma=errors, p0=initial_guess, bounds=bounds)\n",
    "    total = sum(popt)\n",
    "    normalized_popt = popt / total if total > 0 else popt \n",
    "\n",
    "    # Calculate uncertainties for each helicity fraction\n",
    "    uncertainties = np.sqrt(np.diag(pcov)) / total if total > 0 else np.sqrt(np.diag(pcov))\n",
    "\n",
    "    dof = len(hist_values) - len(popt)\n",
    "    reduced_chi_squared = calculate_reduced_chi_squared(hist_values, helicity_function(bin_centers, *popt), errors, dof)\n",
    "\n",
    "    # Plot fitted curve\n",
    "    ax.plot(bin_centers, helicity_function(bin_centers, *popt), color='red', label='Fit', linewidth=2)\n",
    "    \n",
    "    # Annotate with helicity fractions, uncertainties, and reduced chi-squared\n",
    "    ax.text(0.5, 0.9, f\"$f_L$ = {normalized_popt[0]:.3f} ± {uncertainties[0]:.3f}\", transform=ax.transAxes, fontsize=12, ha='center')\n",
    "    ax.text(0.5, 0.85, f\"$f_R$ = {normalized_popt[1]:.3f} ± {uncertainties[1]:.3f}\", transform=ax.transAxes, fontsize=12, ha='center')\n",
    "    ax.text(0.5, 0.8, f\"$f_0$ = {normalized_popt[2]:.3f} ± {uncertainties[2]:.3f}\", transform=ax.transAxes, fontsize=12, ha='center')\n",
    "    ax.text(0.5, 0.75, f\"$\\chi^2_{{r}}$ = {reduced_chi_squared:.3f}\", transform=ax.transAxes, fontsize=12, ha='center')\n",
    "\n",
    "    ax.set_xlabel(r'cos($\\theta^*$)', fontsize=14)\n",
    "    ax.set_ylabel(r'$\\frac{1}{\\sigma}\\frac{d\\sigma}{d(\\cos \\theta^*)}$', fontsize=16)\n",
    "    ax.set_title(f\"Helicity Fit {boson_type} Boson\", fontsize=16, pad=20)\n",
    "    ax.legend(loc='upper right')\n",
    "    ax.grid(True, linestyle='--', linewidth=0.5, alpha=0.7)\n",
    "\n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Define save path relative to current directory, with sanitized boson type\n",
    "    save_dir = f\"./Plots/{com_energy}TeV/Helicity Fractions\"\n",
    "    os.makedirs(save_dir, exist_ok=True)  # Create the directory if it doesn't exist\n",
    "    sanitized_boson_type = boson_type.replace(\"+\", \"plus\").replace(\"-\", \"minus\")  # Remove symbols for filename\n",
    "    save_path = os.path.join(save_dir, f\"Helicity_Distribution_{sanitized_boson_type}_{com_energy}TeV.png\")\n",
    "\n",
    "    # Save the plot\n",
    "    plt.savefig(save_path, dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "    return normalized_popt, uncertainties\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_cos_distribution(theta_data, cross_section, com_energy, num_events, decay_product=\"\"):\n",
    "    \"\"\"\n",
    "    Plots theta and cos(theta) distributions with error bars and saves to a local file path.\n",
    "    \n",
    "    Parameters:\n",
    "    - theta_data: Array of theta angles in radians.\n",
    "    - cross_section: Cross section of the process (e.g., in fb or pb).\n",
    "    - com_energy: Center of mass energy (e.g., in TeV).\n",
    "    - num_events: Total number of events, used for weighting the histogram.\n",
    "    - decay_product: String representing the decay product (e.g., \"mu\" for muon), used as a subscript in labels.\n",
    "    \"\"\"\n",
    "    # Calculate luminosity\n",
    "    luminosity = num_events / cross_section\n",
    "    \n",
    "    # Compute cos(theta) for the second histogram\n",
    "    cos_theta_data = np.cos(theta_data)\n",
    "    \n",
    "    # Set up the figure\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Plot for theta with specific weights and error bars\n",
    "    plt.subplot(1, 2, 1)\n",
    "    raw_counts_theta, bin_edges_theta = np.histogram(theta_data, bins=100, range=(0, np.pi))\n",
    "    bin_centers_theta = 0.5 * (bin_edges_theta[1:] + bin_edges_theta[:-1])\n",
    "    bin_width_theta = bin_edges_theta[1] - bin_edges_theta[0]         \n",
    "\n",
    "    # Define weight per event for the theta plot\n",
    "    weight_per_event_theta = 1 / (luminosity * bin_width_theta * cross_section)\n",
    "\n",
    "    # Calculate weighted counts and errors for theta\n",
    "    counts_theta = raw_counts_theta * weight_per_event_theta\n",
    "    errors_theta = np.sqrt(raw_counts_theta) * weight_per_event_theta  # Weighted errors\n",
    "\n",
    "    # Plot with weighted counts and error bars for theta\n",
    "    plt.plot(bin_centers_theta, counts_theta, drawstyle='steps-mid', color='blue', linewidth=1.5)\n",
    "    plt.errorbar(bin_centers_theta, counts_theta, yerr=errors_theta, fmt='o', color='blue', capsize=3, markersize=4)\n",
    "    plt.xlabel(rf'$\\theta_{{{decay_product}}}$ (radians)')\n",
    "    plt.ylabel(rf'$\\frac{{d\\sigma}}{{d\\theta_{{{decay_product}}}}}$')\n",
    "    plt.title(rf'Angular Distribution of $\\theta_{{{decay_product}}}$', fontsize=14)\n",
    "    \n",
    "    # Plot for cos(theta) with specific weights and error bars\n",
    "    plt.subplot(1, 2, 2)\n",
    "    raw_counts_cos_theta, bin_edges_cos_theta = np.histogram(cos_theta_data, bins=100, range=(-1, 1))\n",
    "    bin_centers_cos_theta = 0.5 * (bin_edges_cos_theta[1:] + bin_edges_cos_theta[:-1])  # Calculate bin centers\n",
    "    bin_width_cos_theta = bin_edges_cos_theta[1] - bin_edges_cos_theta[0]               # Bin width for cos(theta)\n",
    "\n",
    "    # Define weight per event for the cos(theta) plot\n",
    "    weight_per_event_cos_theta = 1 / (luminosity * bin_width_cos_theta * cross_section)\n",
    "\n",
    "    # Calculate weighted counts and errors for cos(theta)\n",
    "    counts_cos_theta = raw_counts_cos_theta * weight_per_event_cos_theta\n",
    "    errors_cos_theta = np.sqrt(raw_counts_cos_theta) * weight_per_event_cos_theta  # Weighted errors\n",
    "\n",
    "    # Plot with weighted counts and error bars for cos(theta)\n",
    "    plt.plot(bin_centers_cos_theta, counts_cos_theta, drawstyle='steps-mid', color='red', linewidth=1.5)\n",
    "    plt.errorbar(bin_centers_cos_theta, counts_cos_theta, yerr=errors_cos_theta, fmt='o', color='red', capsize=3, markersize=4)\n",
    "    plt.xlabel(rf'$\\cos(\\theta_{{{decay_product}}})$')\n",
    "    plt.ylabel(rf'$\\frac{{d\\sigma}}{{d\\cos(\\theta_{{{decay_product}}})}}$')\n",
    "    plt.title(rf'Angular Distribution of $\\cos(\\theta_{{{decay_product}}})$', fontsize=14)\n",
    "    \n",
    "    # Add text for cross-section and center of mass energy\n",
    "    plt.suptitle(f'Angular Distributions\\nCross Section: {cross_section} fb, Center of Mass Energy: {com_energy} TeV',\n",
    "                 fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # Adjust layout\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "\n",
    "    # Define save path relative to current directory, replacing any characters that may interfere with the path\n",
    "    save_dir = f\"./Plots/{com_energy}TeV/Theta Distribution\"\n",
    "    os.makedirs(save_dir, exist_ok=True)  # Create the directory if it doesn't exist\n",
    "    sanitized_decay_product = decay_product.replace(\"\\\\\", \"\").replace(\"^\", \"\")  # Remove LaTeX characters for filename\n",
    "    save_path = os.path.join(save_dir, f\"Theta_Distribution_{sanitized_decay_product}_{com_energy}TeV.png\")\n",
    "\n",
    "    # Save the plot\n",
    "    plt.savefig(save_path, dpi=300)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_phi_distribution(phi_data, cross_section, com_energy, num_events, decay_product=\"\"):\n",
    "    \"\"\"\n",
    "    Plots the angular distribution for phi with error bars and a residuals plot, saving the plot locally.\n",
    "    \n",
    "    Parameters:\n",
    "    - phi_data: Array of phi angles in radians.\n",
    "    - cross_section: Cross section of the process (e.g., in fb or pb).\n",
    "    - com_energy: Center of mass energy (e.g., in TeV).\n",
    "    - num_events: Total number of events, used for weighting the histogram.\n",
    "    - decay_product: String representing the decay product (e.g., \"mu\" for muon), used as a subscript in labels.\n",
    "    \"\"\"\n",
    "    # Calculate luminosity\n",
    "    luminosity = num_events / cross_section\n",
    "    \n",
    "    # Set up the figure with main plot and residuals plot\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(8, 8), gridspec_kw={'height_ratios': [3, 1]}, sharex=True)\n",
    "    \n",
    "    # Histogram for phi with specific weights and error bars\n",
    "    raw_counts_phi, bin_edges_phi = np.histogram(phi_data, bins=100, range=(-np.pi, np.pi))\n",
    "    bin_centers_phi = 0.5 * (bin_edges_phi[1:] + bin_edges_phi[:-1])  # Calculate bin centers\n",
    "    bin_width_phi = bin_edges_phi[1] - bin_edges_phi[0]               # Calculate bin width\n",
    "    \n",
    "    # Define weight per event for the phi plot\n",
    "    weight_per_event_phi = 1 / (luminosity * bin_width_phi * cross_section)\n",
    "    \n",
    "    # Calculate weighted counts and errors for phi\n",
    "    counts_phi = raw_counts_phi * weight_per_event_phi\n",
    "    errors_phi = np.sqrt(raw_counts_phi) * weight_per_event_phi  # Weighted errors\n",
    "    \n",
    "    # Plot with weighted counts and error bars for phi\n",
    "    ax1.plot(bin_centers_phi, counts_phi, drawstyle='steps-mid', color='purple', linewidth=1.5)\n",
    "    ax1.errorbar(bin_centers_phi, counts_phi, yerr=errors_phi, fmt='o', color='purple', capsize=3, markersize=4)\n",
    "    ax1.set_ylabel(rf'$\\frac{{d\\sigma}}{{d\\phi_{{{decay_product}}}}}$')\n",
    "    ax1.set_title(rf'Angular Distribution of $\\phi_{{{decay_product}}}$', fontsize=14)\n",
    "    \n",
    "    # Reference line (mean of the weighted counts)\n",
    "    mean_value = np.mean(counts_phi)\n",
    "    ax1.axhline(mean_value, color='gray', linestyle='--', label='Mean Value')\n",
    "    ax1.legend()\n",
    "    \n",
    "    # Calculate residuals as (observed - mean)\n",
    "    residuals_phi = counts_phi - mean_value\n",
    "    \n",
    "    # Plot residuals with error bars\n",
    "    ax2.errorbar(bin_centers_phi, residuals_phi, yerr=errors_phi, fmt='o', color='purple', capsize=3, markersize=4)\n",
    "    ax2.axhline(0, color='black', linestyle='--')\n",
    "    ax2.set_xlabel(rf'$\\phi_{{{decay_product}}}$ (radians)')\n",
    "    ax2.set_ylabel('Residuals')\n",
    "\n",
    "    # Add text for cross-section and center of mass energy\n",
    "    fig.suptitle(f'Phi Angular Distribution with Residuals\\nCross Section: {cross_section} fb, Center of Mass Energy: {com_energy} TeV',\n",
    "                 fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # Adjust layout\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "\n",
    "    # Define save path relative to the current directory, with a sanitized decay product\n",
    "    save_dir = f\"./Plots/{com_energy}TeV/Phi Distribution\"\n",
    "    os.makedirs(save_dir, exist_ok=True)  # Create the directory if it doesn't exist\n",
    "    sanitized_decay_product = decay_product.replace(\"\\\\\", \"\").replace(\"^\", \"\")  # Remove LaTeX characters for filename\n",
    "    save_path = os.path.join(save_dir, f\"Phi_Distribution_{sanitized_decay_product}_{com_energy}TeV.png\")\n",
    "\n",
    "    # Save the plot\n",
    "    plt.savefig(save_path, dpi=300)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_boosts(four_momenta, com_momentum, z_axis, transform_func):\n",
    "    boosted_momenta = {}\n",
    "    for name, momentum in four_momenta.items():\n",
    "        boosted_momenta[name] = transform_func(momentum, com_momentum, z_axis)\n",
    "    return boosted_momenta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 13.6 TeV\n",
      "Warning: Rotation check failed at Index 126745.Calculated angle: 1.2074182697257333e-06 degrees.\n",
      "Warning: Rotation check failed at Index 134145.Calculated angle: 1.2074182697257333e-06 degrees.\n",
      "Warning: Rotation check failed at Index 351795.Calculated angle: 1.2074182697257333e-06 degrees.\n",
      "Warning: Rotation check failed at Index 126745.Calculated angle: 1.2074182697257333e-06 degrees.\n",
      "Warning: Rotation check failed at Index 134145.Calculated angle: 1.2074182697257333e-06 degrees.\n",
      "Warning: Rotation check failed at Index 351795.Calculated angle: 1.2074182697257333e-06 degrees.\n",
      "Warning: Rotation check failed at Index 126745.Calculated angle: 1.2074182697257333e-06 degrees.\n",
      "Warning: Rotation check failed at Index 134145.Calculated angle: 1.2074182697257333e-06 degrees.\n",
      "Warning: Rotation check failed at Index 351795.Calculated angle: 1.2074182697257333e-06 degrees.\n",
      "Warning: Rotation check failed at Index 126745.Calculated angle: 1.2074182697257333e-06 degrees.\n",
      "Warning: Rotation check failed at Index 134145.Calculated angle: 1.2074182697257333e-06 degrees.\n",
      "Warning: Rotation check failed at Index 351795.Calculated angle: 1.2074182697257333e-06 degrees.\n",
      "Warning: Rotation check failed at Index 126745.Calculated angle: 1.2074182697257333e-06 degrees.\n",
      "Warning: Rotation check failed at Index 134145.Calculated angle: 1.2074182697257333e-06 degrees.\n",
      "Warning: Rotation check failed at Index 351795.Calculated angle: 1.2074182697257333e-06 degrees.\n",
      "Warning: Rotation check failed at Index 126745.Calculated angle: 1.2074182697257333e-06 degrees.\n",
      "Warning: Rotation check failed at Index 134145.Calculated angle: 1.2074182697257333e-06 degrees.\n",
      "Warning: Rotation check failed at Index 351795.Calculated angle: 1.2074182697257333e-06 degrees.\n",
      "Warning: Rotation check failed at Index 126745.Calculated angle: 1.2074182697257333e-06 degrees.\n",
      "Warning: Rotation check failed at Index 134145.Calculated angle: 1.2074182697257333e-06 degrees.\n",
      "Warning: Rotation check failed at Index 351795.Calculated angle: 1.2074182697257333e-06 degrees.\n",
      "Warning: Rotation check failed at Index 126745.Calculated angle: 1.2074182697257333e-06 degrees.\n",
      "Warning: Rotation check failed at Index 134145.Calculated angle: 1.2074182697257333e-06 degrees.\n",
      "Warning: Rotation check failed at Index 351795.Calculated angle: 1.2074182697257333e-06 degrees.\n",
      "Warning: Rotation check failed at Index 126745.Calculated angle: 1.2074182697257333e-06 degrees.\n",
      "Warning: Rotation check failed at Index 134145.Calculated angle: 1.2074182697257333e-06 degrees.\n",
      "Warning: Rotation check failed at Index 351795.Calculated angle: 1.2074182697257333e-06 degrees.\n",
      "Processing 14.0 TeV\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import vector  # Assuming vector is being used for four-vector operations\n",
    "\n",
    "# Define your particle IDs for easy reuse\n",
    "particle_ids = {\n",
    "    \"z\": 23, \"muon\": 13, \"anti_muon\": -13, \"w\": 24, \"electron_neutrino\": 12, \n",
    "    \"anti_electron\": -11, \"w_anti\": -24, \"electron\": 11, \"anti_electron_neutrino\": -12\n",
    "}\n",
    "\n",
    "def process_energy(lhe_file):\n",
    "    # Extract particle data and metadata\n",
    "    all_particle_data = extract_all_particle_data(lhe_file)\n",
    "    metadata = extract_metadata_from_lhe(lhe_file)\n",
    "    \n",
    "    CrossSection = metadata[\"cross_section\"]\n",
    "    CentreOfMassEnergy = metadata[\"center_of_mass_energy\"]\n",
    "    NumberOfEvents = metadata[\"number_of_events\"]\n",
    "\n",
    "    # Filter and organize data by particle\n",
    "    particle_data = {name: filter_by_id(all_particle_data, pid) for name, pid in particle_ids.items()}\n",
    "    four_momenta = {name: construct_four_vector(data) for name, data in particle_data.items()}\n",
    "    com_four_momentum = four_momenta[\"z\"] + four_momenta[\"w\"] + four_momenta[\"w_anti\"]\n",
    "    z_axis = vector.obj(px=0, py=0, pz=1)\n",
    "    \n",
    "    # Apply transformations\n",
    "    boosted_momenta_1 = apply_boosts(four_momenta, com_four_momentum, z_axis, rotate_and_boost)\n",
    "    \n",
    "    # Z boson decay products\n",
    "    muon_rest = rotate_and_boost(boosted_momenta_1[\"muon\"], boosted_momenta_1[\"z\"], z_axis)\n",
    "    anti_muon_rest = rotate_and_boost(boosted_momenta_1[\"anti_muon\"], boosted_momenta_1[\"z\"], z_axis)\n",
    "    \n",
    "    # W boson decay products\n",
    "    electron_neutrino_rest = rotate_and_boost(boosted_momenta_1[\"electron_neutrino\"], boosted_momenta_1[\"w\"], z_axis)\n",
    "    anti_electron_rest = rotate_and_boost(boosted_momenta_1[\"anti_electron\"], boosted_momenta_1[\"w\"], z_axis)\n",
    "    \n",
    "    # Anti-W boson decay products\n",
    "    electron_rest = rotate_and_boost(boosted_momenta_1[\"electron\"], boosted_momenta_1[\"w_anti\"], z_axis)\n",
    "    anti_electron_neutrino_rest = rotate_and_boost(boosted_momenta_1[\"anti_electron_neutrino\"], boosted_momenta_1[\"w_anti\"], z_axis)\n",
    "\n",
    "    # Angle calculations\n",
    "    angles = {\n",
    "        \"muon_polar\": find_polar_angle(muon_rest),\n",
    "        \"anti_muon_polar\": find_polar_angle(anti_muon_rest),\n",
    "        \"electron_neutrino_polar\": find_polar_angle(electron_neutrino_rest),\n",
    "        \"anti_electron_polar\": find_polar_angle(anti_electron_rest),\n",
    "        \"electron_polar\": find_polar_angle(electron_rest),\n",
    "        \"anti_electron_neutrino_polar\": find_polar_angle(anti_electron_neutrino_rest),\n",
    "        \"muon_azimuthal\": find_azimuthal_angle(muon_rest),\n",
    "        \"anti_muon_azimuthal\": find_azimuthal_angle(anti_muon_rest),\n",
    "        \"electron_neutrino_azimuthal\": find_azimuthal_angle(electron_neutrino_rest),\n",
    "        \"anti_electron_azimuthal\": find_azimuthal_angle(anti_electron_rest),\n",
    "        \"electron_azimuthal\": find_azimuthal_angle(electron_rest),\n",
    "        \"anti_electron_neutrino_azimuthal\": find_azimuthal_angle(anti_electron_neutrino_rest)\n",
    "    }\n",
    "\n",
    "    # Perform momentum conservation checks\n",
    "    momentum_checks = {\n",
    "        \"z_decay\": momentum_conservation_check(muon_rest, anti_muon_rest),\n",
    "        \"w_decay\": momentum_conservation_check(electron_neutrino_rest, anti_electron_rest),\n",
    "        \"w_anti_decay\": momentum_conservation_check(electron_rest, anti_electron_neutrino_rest)\n",
    "    }\n",
    "\n",
    "    return {\n",
    "        \"metadata\": metadata,\n",
    "        \"four_momenta\": four_momenta,\n",
    "        \"angles\": angles,\n",
    "        \"momentum_checks\": momentum_checks\n",
    "    }\n",
    "\n",
    "def process_multiple_energies(energy_files):\n",
    "    \"\"\"\n",
    "    Processes data for multiple energy levels and stores the results in a dictionary.\n",
    "\n",
    "    Parameters:\n",
    "        energy_files (dict): Dictionary where keys are energy levels (e.g., 13.6) and values are LHE file paths.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary with results for each energy level.\n",
    "    \"\"\"\n",
    "    results_by_energy = {}\n",
    "    for energy, lhe_file in energy_files.items():\n",
    "        print(f\"Processing {energy} TeV\")\n",
    "        results_by_energy[energy] = process_energy(lhe_file)\n",
    "    return results_by_energy\n",
    "\n",
    "# Usage example\n",
    "energy_files = {\n",
    "    13.6:  r\"C:\\Users\\gabri\\Documents\\University\\Year 4\\Mphys\\DataFiles\\wwz_500k_13.6TeV.lhe\",\n",
    "    14.0:  r\"C:\\Users\\gabri\\Documents\\University\\Year 4\\Mphys\\DataFiles\\wwz_500k_14TeV.lhe\"\n",
    "}\n",
    "\n",
    "results = process_multiple_energies(energy_files)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Mphys",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
